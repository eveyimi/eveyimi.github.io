I"iÃ<p>Hello, welcome to my blog! This post will share the data manipulation of <strong><a href="https://www.insectimages.org/index.cfm">Insects Image Classification</a></strong>.</p>

<p>Please visit my <strong><a href="https://github.com/eveyimi/eveyimi.github.io">GitHub</a></strong> for more information.</p>

<h1 id="introduction">Introduction</h1>

<p>The data is extracted from Bugwood Images, which is a grant-funded project that was started in 1994 by the University of Georgiaâ€™s Center for Invasive Species and Ecosystem Health. The focus of Bugwood Images is on species of economic concern. Images cover invasive species, forestry, agriculture, integrated pest management, plants, insects, diseases, fungi, wildlife, fire and other natural resource issues. For this post, we will focus on insect images, mainly including three kindsâ€“beetles, cockroach and dragonflies. I will first train a Convolutional Neural Network (CNN) to classify insect images. In the second part, I will use an image classification model from TensorFlow Hub and do transfer learning to fine-tune the model for specific image classes.</p>

<h1 id="convolutional-neural-network-classification">Convolutional Neural Network classification</h1>
<p>Convolutional Neural Network is a neural network in which at least one layer is a convolutional layer. A typical convolutional neural network consists of some combination of the following layers: convolutional layers, pooling layers, dense layers. Convolutional neural networks have had great success in certain kinds of problems, such as image recognition.</p>

<h2 id="0-set-up">0. Set up</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">PIL</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span></code></pre></figure>

<h2 id="1-load-data">1. Load data</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pathlib</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="s">"insects/train"</span><span class="p">)</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="s">"insects/test"</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">img_height</span> <span class="o">=</span> <span class="mi">180</span>
<span class="n">img_width</span> <span class="o">=</span> <span class="mi">180</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">train_dir</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
    <span class="n">test_dir</span><span class="p">,</span>
    <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span></code></pre></figure>

<p>Since we already have the train and test datasets, we donâ€™t have to split them. We can then take a look of the insects in train and test directories.</p>

<h4 id="train-dataset-images">train dataset images</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">train_ds</span><span class="p">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">numpy</span><span class="p">().</span><span class="n">astype</span><span class="p">(</span><span class="s">"uint8"</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'train.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/train.png" alt="1" /></p>

<h4 id="test-dataset-images">test dataset images</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">test_ds</span><span class="p">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">numpy</span><span class="p">().</span><span class="n">astype</span><span class="p">(</span><span class="s">"uint8"</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'test.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/test.png" alt="2" /></p>

<h2 id="2-configure-the-dataset-for-performance">2. Configure the dataset for performance</h2>
<p>We want to use buffered prefetching to yield data from disk without having I/O become blocking.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">.</span><span class="n">cache</span><span class="p">().</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">).</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="p">.</span><span class="n">cache</span><span class="p">().</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span></code></pre></figure>

<h2 id="3-create-the-model">3. Create the model</h2>
<p>The model consists of three convolution blocks with a max pool layer in each of them. Thereâ€™s a fully connected layer with 128 units on top of it that is activated by a <code class="language-plaintext highlighter-rouge">relu</code> activation function. <code class="language-plaintext highlighter-rouge">Conv2D</code> is a 2D convolution layer (e.g. spatial convolution over images). This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. <code class="language-plaintext highlighter-rouge">MaxPool2D</code> is Max pooling operation for 2D spatial data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># we have three classes
</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="p">])</span></code></pre></figure>

<h2 id="4-compile-the-model">4. Compile the model</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span></code></pre></figure>

<h4 id="model-summary">Model summary</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    rescaling_1 (Rescaling)      (None, 180, 180, 3)       0         
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 180, 180, 16)      448       
    _________________________________________________________________
    max_pooling2d_3 (MaxPooling2 (None, 90, 90, 16)        0         
    _________________________________________________________________
    conv2d_4 (Conv2D)            (None, 90, 90, 32)        4640      
    _________________________________________________________________
    max_pooling2d_4 (MaxPooling2 (None, 45, 45, 32)        0         
    _________________________________________________________________
    conv2d_5 (Conv2D)            (None, 45, 45, 64)        18496     
    _________________________________________________________________
    max_pooling2d_5 (MaxPooling2 (None, 22, 22, 64)        0         
    _________________________________________________________________
    flatten_1 (Flatten)          (None, 30976)             0         
    _________________________________________________________________
    dense_2 (Dense)              (None, 128)               3965056   
    _________________________________________________________________
    dense_3 (Dense)              (None, 3)                 387       
    =================================================================
    Total params: 3,989,027
    Trainable params: 3,989,027
    Non-trainable params: 0
    _________________________________________________________________
</code></pre></div></div>

<p><br />
Based on the model summary, we can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as going deeper in the network. We added dense layers on top and feed the last output tensor from the convolutional base into one or more Dense layers to perform classification.</p>

<h2 id="5-train-the-model">5. Train the model</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">test_ds</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span>
<span class="p">)</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 1/10
    32/32 [==============================] - 8s 252ms/step - loss: 0.9014 - accuracy: 0.6487 - val_loss: 0.6370 - val_accuracy: 0.7722
    Epoch 2/10
    32/32 [==============================] - 8s 247ms/step - loss: 0.4568 - accuracy: 0.8234 - val_loss: 0.5376 - val_accuracy: 0.8333
    Epoch 3/10
    32/32 [==============================] - 8s 249ms/step - loss: 0.3298 - accuracy: 0.8803 - val_loss: 0.3938 - val_accuracy: 0.8722
    Epoch 4/10
    32/32 [==============================] - 8s 251ms/step - loss: 0.2366 - accuracy: 0.9097 - val_loss: 0.2523 - val_accuracy: 0.9111
    Epoch 5/10
    32/32 [==============================] - 8s 250ms/step - loss: 0.1741 - accuracy: 0.9441 - val_loss: 0.2255 - val_accuracy: 0.9167
    Epoch 6/10
    32/32 [==============================] - 8s 251ms/step - loss: 0.1165 - accuracy: 0.9598 - val_loss: 0.1234 - val_accuracy: 0.9556
    Epoch 7/10
    32/32 [==============================] - 8s 251ms/step - loss: 0.1012 - accuracy: 0.9607 - val_loss: 0.1412 - val_accuracy: 0.9556
    Epoch 8/10
    32/32 [==============================] - 8s 251ms/step - loss: 0.0674 - accuracy: 0.9715 - val_loss: 0.0765 - val_accuracy: 0.9778
    Epoch 9/10
    32/32 [==============================] - 8s 252ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 0.0464 - val_accuracy: 0.9833
    Epoch 10/10
    32/32 [==============================] - 8s 254ms/step - loss: 0.0259 - accuracy: 0.9961 - val_loss: 0.0339 - val_accuracy: 0.9944
</code></pre></div></div>

<p><br /></p>

<h2 id="6-visualize-training-results">6. Visualize training results</h2>
<p>We can create plots of loss and accuracy on the training and test sets.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_accuracy'</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">]</span>

<span class="n">epochs_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation Accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs_range</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/images/HW7/viz1.png" alt="3" /></p>

<p>As we can see from the plots, training accuracy and validation accuracy are matched well and the model has achieved high accuracy on validation dataset which is over 95%. In summary, CNN works well on insects classification.</p>

<h1 id="transfer-learning-with-tensorflow-hub">Transfer learning with TensorFlow Hub</h1>
<p><strong><a href="https://www.tensorflow.org/hub">TensorFlow Hub</a></strong> is a repository of pre-trained TensorFlow models for reusable machine learning. The tfhub.dev repository provides many pre-trained models: text embeddings, image classification models, TF.js/TFLite models and much more.</p>

<blockquote>
  <p>The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.</p>

  <p><cite>https://www.tensorflow.org/</cite></p>
</blockquote>

<p>In this section, I am going to use image classification model from TensorFlow Hub and do transfer learning to fine-tune a model for specific image classes.</p>

<h2 id="0-set-up-1">0. Set up</h2>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">PIL.Image</span> <span class="k">as</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="n">hub</span></code></pre></figure>

<h2 id="1-an-imagenet-classifier">1. An ImageNet classifier</h2>
<h4 id="download-the-classifier">Download the classifier</h4>
<p>Use hub.KerasLayer to load a MobileNetV2 model from TensorFlow Hub.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">classifier_model</span> <span class="o">=</span><span class="s">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"</span> 
<span class="n">IMAGE_SHAPE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">classifier_model</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">IMAGE_SHAPE</span><span class="o">+</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="p">])</span></code></pre></figure>

<h4 id="decode-the-predictions">Decode the predictions</h4>
<p>Take the predicted class ID and fetch the ImageNet labels to decode the predictions.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">labels_path</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span><span class="s">'ImageNetLabels.txt'</span><span class="p">,</span><span class="s">'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'</span><span class="p">)</span>
<span class="n">imagenet_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">labels_path</span><span class="p">).</span><span class="n">read</span><span class="p">().</span><span class="n">splitlines</span><span class="p">())</span></code></pre></figure>

<h2 id="2-transfer-learning">2. Transfer learning</h2>
<h4 id="load-data">Load data</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">img_height</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">img_width</span> <span class="o">=</span> <span class="mi">224</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="s">"insects/train"</span><span class="p">)</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="p">.</span><span class="n">Path</span><span class="p">(</span><span class="s">"insects/test"</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image_dataset_from_directory</span><span class="p">(</span>
  <span class="n">train_dir</span><span class="p">,</span>
  <span class="n">image_size</span><span class="o">=</span><span class="p">(</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">),</span>
  <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="c1"># &gt;&gt;&gt; Found 1019 files belonging to 3 classes.
</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ds</span><span class="p">.</span><span class="n">class_names</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>
<span class="c1"># &gt;&gt;&gt; ['beetles' 'cockroach' 'dragonflies']
</span>
<span class="c1"># Use the Rescaling layer
</span><span class="n">normalization_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">Rescaling</span><span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">normalization_layer</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span></code></pre></figure>

<p>As with part 1, I use buffered prefetching to yield data from disk without having I/O become blocking.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">.</span><span class="n">cache</span><span class="p">().</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span></code></pre></figure>

<h4 id="run-the-classifier-on-a-batch-of-images">Run the classifier on a batch of images</h4>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">result_batch</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>
<span class="n">predicted_class_names</span> <span class="o">=</span> <span class="n">imagenet_labels</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result_batch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">predicted_class_names</span>
<span class="c1"># &gt;&gt;&gt; array(['bonnet', 'cockroach', 'damselfly', ..., 'spindle', 'lacewing','slug'], dtype='&lt;U30')</span></code></pre></figure>

<p>We can check the prediction results with visualization.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_batch</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">predicted_class_names</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"ImageNet predictions"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'batch_pred.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/batch_pred.png" alt="3" /></p>

<p>The results might seem not that good. Letâ€™s move to the next section.</p>

<h2 id="3-a-headless-model">3. A headless model</h2>
<p>TensorFlow Hub also distributes models without the top classification layer. These can be used to easily do transfer learning.</p>
<h3 id="download-the-headless-model">Download the headless model</h3>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">feature_extractor_model</span> <span class="o">=</span> <span class="s">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"</span> 
<span class="n">feature_extractor_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">(</span>
    <span class="n">feature_extractor_model</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">feature_batch</span> <span class="o">=</span> <span class="n">feature_extractor_layer</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">feature_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (32, 1280)
</code></pre></div></div>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
  <span class="n">feature_extractor_layer</span><span class="p">,</span>
  <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    keras_layer_2 (KerasLayer)   (None, 1280)              2257984   
    _________________________________________________________________
    dense (Dense)                (None, 3)                 3843      
    =================================================================
    Total params: 2,261,827
    Trainable params: 3,843
    Non-trainable params: 2,257,984
    _________________________________________________________________
</code></pre></div></div>

<p><br /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">.</span><span class="n">shape</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    TensorShape([32, 3])
</code></pre></div></div>

<p><br /></p>

<p>We then compile and fit the model.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
  <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(),</span>
  <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'acc'</span><span class="p">])</span>

<span class="k">class</span> <span class="nc">CollectBatchStats</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_acc</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_losses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s">'loss'</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_acc</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s">'acc'</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

<span class="n">batch_stats_callback</span> <span class="o">=</span> <span class="n">CollectBatchStats</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">batch_stats_callback</span><span class="p">])</span></code></pre></figure>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 1/2
    32/32 [=========================] - 8s 239ms/step - loss: 0.1042 - acc: 1.0000
    Epoch 2/2
    32/32 [=========================] - 8s 236ms/step - loss: 0.0410 - acc: 1.0000
</code></pre></div></div>

<p><br /></p>

<p>We then visualize the results.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Training Steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">batch_stats_callback</span><span class="p">.</span><span class="n">batch_losses</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'loss.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/loss.png" alt="3" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Training Steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">batch_stats_callback</span><span class="p">.</span><span class="n">batch_acc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'acc.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/acc.png" alt="3" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">predicted_batch</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)</span>
<span class="n">predicted_id</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_batch</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">predicted_label_batch</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">predicted_id</span><span class="p">]</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">30</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image_batch</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">predicted_label_batch</span><span class="p">[</span><span class="n">n</span><span class="p">].</span><span class="n">title</span><span class="p">())</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"Model predictions"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'model_pred.png'</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/HW7/model_pred.png" alt="3" /></p>

:ET